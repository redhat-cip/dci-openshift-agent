---
- name: Validate we have all the pieces to run in disconnected mode
  assert:
    that:
      - webserver_url is defined
      - groups['registry_host'] is defined
      - groups['registry_host'] | length > 0
      - dci_local_registry | length
      - provision_cache_store is defined
  when:
    - dci_disconnected | default(false) | bool

- name: "Assert that operator_catalog_dir exists and has tar files"
  find:
    path: "{{ operator_catalog_dir }}"
    recurse: true
    patterns: "*.tar"
  register: catalog_path
  failed_when:
    - catalog_path is undefined or
      catalog_path.matched == 0
  when:
    - operator_catalog_dir | length

- name: "Validate NFS provisioner variables"
  assert:
    that:
      - nfs_server is defined
      - nfs_server | length > 0
      - nfs_path is defined
      - nfs_path | length > 0
  when:
    - enable_nfs_storage | bool

- name: "Validate Logging Subsystem variables"
  block:
    - name: "Check logs_settings file"
      stat:
        path: "{{ logs_settings }}"
      register: file_stat
      when:
        - logs_settings is defined
        - logs_settings | default("") | length

    - name: "Load logs_settings from vars file"
      include_vars:
        file: "{{ logs_settings }}"
      when:
        - logs_settings is defined
        - logs_settings | default("") | length
        - file_stat is defined
        - file_stat.stat.exists

    - name: "Validate Logging Subsystem variables"
      assert:
        that: "{{ item }} is defined"
        fail_msg: "The parameter {{ item }} is required"
      with_items:
        - logs_access_key_id
        - logs_access_key_secret
        - logs_bucket
        - logs_endpoint
        - logs_region
        - logs_loki_size
        - logs_storage_class
  when:
    - enable_logs_stack | bool

- name: "Set pullsecret from job_info - Connected"
  set_fact:
    pullsecret: "{{ job_info.job.topic.data.pull_secret | default({}) | combine(openshift_secret | default({}), recursive=True) }}"
  no_log: true
  when:
    - not (dci_disconnected | default(false) | bool)

# Removing secret for cloud.openshift.com in order to disable the insights operator
- name: "Set pullsecret from job_info - Disconnected"
  vars:
    dci_pullsecret: "{{ job_info.job.topic.data.pull_secret | default({}) | combine(openshift_secret | default({}), recursive=True) }}"
  set_fact:
    pullsecret: |
      {
        "auths": {
        {% for repo in dci_pullsecret.auths | list %}
          {% if repo != "cloud.openshift.com" %}
            "{{ repo }}": {{ dci_pullsecret.auths[repo] | to_json }}{% if loop.last %}{% else %},{% endif %}
          {% endif %}
        {% endfor %}
        }
      }
  no_log: true
  when:
    - dci_disconnected | default(false) | bool

- name: "Read Disconnected auths"
  include_vars:
    file: "{{ hostvars[groups['registry_host'][0]].disconnected_registry_auths_file }}"
    name: disconnected_auths
  no_log: true
  when:
    - dci_disconnected | default(false) | bool

- name: "Check if {{ pullsecret_file }} exists"
  stat:
    path: "{{ pullsecret_file }}"
    get_checksum: false
  register: pullfile
  when:
    - pullsecret_file is defined

- name: "Override Job pull secret with what is defined in pullsecret_file var"
  block:
    - name: "Copy pull secret file to cache directory"
      copy:
        src: "{{ pullsecret_file }}"
        dest: "{{ dci_cluster_configs_dir }}/pull-secret.txt"
        owner: "{{ ansible_user_id }}"
        group: "{{ ansible_user_gid }}"
        mode: "0400"
        force: true
  when:
    - pullsecret_file is defined
    - pullfile.stat.exists | bool

- name: "Combine Job pullsecret and disconnected_auths"
  block:
    - name: "Combine secrets"
      set_fact:
        auths: "{{ pullsecret | combine({'auths': disconnected_auths}, recursive=True) }}"
      no_log: true

    - name: "Save combined secrets to a file"
      copy:
        content: "{{ auths }}"
        dest: "{{ dci_cluster_configs_dir }}/pull-secret.txt"
        owner: "{{ ansible_user_id }}"
        group: "{{ ansible_user_gid }}"
        mode: "0400"
        force: true
  when:
    - dci_disconnected | default(false) | bool
    - pullsecret_file is undefined

- name: "Set dci_pullsecret_file in connected environments"
  block:
    - name: "Save Job pullsecret content to a file"
      copy:
        content: "{{ pullsecret }}"
        dest: "{{ dci_cluster_configs_dir }}/pull-secret.txt"
        owner: "{{ ansible_user_id }}"
        group: "{{ ansible_user_gid }}"
        mode: "0400"
        force: true
  when:
    - not (dci_disconnected | default(false) | bool)
    - pullsecret_file is undefined

- name: "Set dci_pullsecret_file"
  set_fact:
    dci_pullsecret_file: "{{ dci_cluster_configs_dir }}/pull-secret.txt"

- name: "Create releases dir in home directory if needed"
  file:
    path: "{{ (ansible_env.HOME, 'releases') | join('/') }}"
    state: directory
    setype: "container_file_t"
    mode: "0775"
  when:
    - provision_cache_store is undefined

- name: Mirror release
  include_role:
    name: mirror-ocp-release
  vars:
    mor_version: "{{ version }}"
    mor_pull_url: "{{ version_pull_url }}"
    mor_cache_dir: "{{ provision_cache_store | default((ansible_env.HOME, 'releases') | join('/')) }}"
    mor_webserver_url: "{{ webserver_url | default(None) }}"
    mor_registry_url: "{{ dci_local_registry }}"
    mor_registry_path: "{{ hostvars[groups['registry_host'][0]].local_repo | default( 'ocp-'+ version.split('.')[:2] | join('.') +'/'+ version, true) }}"
    mor_auths_file: "{{ dci_pullsecret_file }}"
    mor_force: "{{ (dci_force_mirroring | default(false)) or (build == 'candidate') | bool }}"
    mor_install_type: "{{ install_type }}"
    mor_mirror_disk_images: "{{ dci_disconnected | default(False) | bool }}"
    mor_mirror_container_images: "{{ dci_disconnected | default(False) | bool }}"
    mor_write_custom_config: "{{ dci_disconnected | default(False) | bool }}"
    mor_build: "{{ build }}"
    mor_oc: "{{ oc_tool_path }}"

- name: Mirror intermediate version for EUS Upgrade
  vars:
    ocp_major: "{{ version.split('.')[0] }}"
    ocp_minor: "{{ version.split('.')[1] }}"
    major_inter: "{{ ocp_major }}.{{ ocp_minor | int - 1 }}"
    version_core: "{{ version.split('.')[:2] | join('.') }}"
  block:
    - name: "Get intermediate release from Graph"
      uri:
        url: https://api.openshift.com/api/upgrades_info/v1/graph?channel=eus-{{ version_core }}&arch=amd64
      register: version_inter_graph

    - name: "Set version_inter from Graph"
      vars:
        graph_versions: "{{ version_inter_graph.json | json_query('nodes[*].version') }}"
        filter_inter: "^{{ major_inter }}"
      set_fact:
        version_inter: "{{ graph_versions | select('match', filter_inter) | list | version_sort | last }}"
      when:
        - version_inter is undefined
        - version_inter_graph.json["nodes"] | length

    - name: "Fail when no intermediate version is provided in the graph"
      fail:
        msg: "No intermediate version found, try defining one with: version_inter={{ major_inter }}.X"
      when:
        - version_inter is undefined
        - not version_inter_graph.json["nodes"] | length

    - name: "Get intermediate component from DCI"
      environment:
        DCI_CLIENT_ID: "{{ dci_client_id }}"
        DCI_API_SECRET: "{{ dci_api_secret }}"
        DCI_CS_URL: "{{ dci_cs_url }}"
      block:
        - name: "Get intermediate topic"
          dci_topic:
            state: search
            name: "OCP-{{ major_inter }}"
          register: inter_topic

        - name: "Get intermediate component"
          dci_component:
            state: search
            topic_id: "{{ inter_topic.topics[0].id }}"
            type: "ocp"
            name: "{{ version_inter }}"
          register: inter_component

    - name: "Get image for intermediate version from DCI"
      set_fact:
        image_inter: "{{ inter_component.components[0].data.pull_url }}"
      when: inter_component.components | length

    - name: "Fail when the intermediate version is not found in DCI"
      fail:
        message: "Unable to find {{ version_inter }} in DCI"
      when: not inter_component.components | length

    - name: "Mirror intermediate OCP release"
      include_role:
        name: mirror-ocp-release
      vars:
        mor_version: "{{ version_inter }}"
        mor_pull_url: "{{ image_inter }}"
        mor_cache_dir: "{{ provision_cache_store | default((ansible_env.HOME, 'releases') | join('/')) }}"
        mor_webserver_url: "{{ webserver_url | default(None) }}"
        mor_registry_url: "{{ dci_local_registry }}"
        mor_registry_path: "{{ hostvars[groups['registry_host'][0]].local_repo | default( 'ocp-'+ version.split('.')[:2] | join('.') +'/'+ version, true) }}"
        mor_auths_file: "{{ dci_pullsecret_file }}"
        mor_force: "{{ (dci_force_mirroring | default(false)) or (build == 'candidate') | bool }}"
        mor_install_type: "{{ install_type }}"
        mor_mirror_disk_images: "{{ dci_disconnected | default(False) | bool }}"
        mor_mirror_container_images: "{{ dci_disconnected | default(False) | bool }}"
        mor_write_custom_config: "{{ dci_disconnected | default(False) | bool }}"
        mor_build: "{{ build }}"
        mor_oc: "{{ oc_tool_path }}"
      when:
        - dci_disconnected | default(false) |  bool
  when:
    - upgrade_eus | default(false) | bool

- name: "Clone/update baremetal-deploy repo"
  vars:
    git_repo: "{{ baremetal_deploy_repo }}"
    git_ref: "{{ baremetal_deploy_version }}"
  git:
    version: "{{ git_ref }}"
    repo: "{{ git_repo }}"
    dest: "{{ dci_cache_dir }}/baremetal_deploy_repo"
    force: true
  register: git_clone
  retries: 3
  delay: 10
  until: not git_clone.failed
  when:
    - install_type == 'ipi'
  tags:
    - clone_upstream_repos

- name: Include installed software as components
  vars:
    mandatory_rpms:
      - ansible
      - dci-ansible
      - dci-openshift-agent
      - dci-pipeline
      - python3-dciclient
      - python3-kubernetes
      - python3-openshift
    ic_rpms: "{{ (dci_rpms_to_components + mandatory_rpms)|flatten }}"
    ic_gits: "{{ dci_gits_to_components|flatten }}"
    ic_dev_gits: "{{ dev_gits_to_components|flatten }}"
  include_role:
    name: include-components

- name: Append mirrors to trust bundle
  block:
    - name: Copy initial trust bundle
      copy:
        src: "{{ hostvars[groups['registry_host'][0]].disconnected_registry_mirrors_file }}"
        dest: "{{ dci_cluster_configs_dir }}/trust-bundle.yml"
        mode: "0644"

    - name: Add mirrors to trust bundle
      vars:
        icsp_path: "{{ provision_cache_store }}/{{ version }}/imagecontentsourcepolicy.yaml"
      copy:
        dest: "{{ dci_cluster_configs_dir }}/trust-bundle.yml"
        mode: "0644"
        content: |
          {{ lookup('file', dci_cluster_configs_dir + '/trust-bundle.yml') }}
          {{ lookup('file', icsp_path ) |
             from_yaml |
             json_query('spec.repositoryDigestMirrors') |
             to_yaml
          }}
  when:
    - dci_disconnected | default(false) | bool

- name: "Mirror must gather images"
  include_role:
    name: mirror_images
  vars:
    images: "{{ dci_must_gather_images | default(['registry.redhat.io/openshift4/ose-must-gather']) }}"
    authfile: "{{ dci_pullsecret_file }}"
  when: >
    (dci_disconnected | default(false) | bool) or
    (dci_local_mirror | default(false) | bool)

- name: Get provisioner SSH identity
  delegate_to: "{{ groups['provisioner'][0] }}"
  fetch:
    src: "~{{ hostvars[groups['provisioner'][0]].ansible_user }}/.ssh/id_rsa"
    dest: "~/.ssh/{{ cluster }}-provisioner_rsa"
    flat: true

- name: Erase bootloader to prevent old OS to boot
  delegate_to: "{{ item }}"
  become: true
  shell: |
    if grep 'Red Hat Enterprise Linux CoreOS' /etc/os-release; then
      for disk in /dev/sd?; do
        dd if=/dev/zero of=$disk bs=512 count=1
      done
    fi
  when:
    - dci_erase_bootloader_on_disk|default(False)|bool
    - dci_main is not defined or dci_main == 'install'
  with_items: "{{ groups['masters'] + groups['workers'] | default([]) }}"
  ignore_unreachable: true
  ignore_errors: true

- name: Empty Console log files if present
  command: dd if=/dev/null of="{{ item }}"
  with_fileglob:
    - "/var/consoles/{{ cluster }}/{{ cluster }}*"
  when:
    - cluster is defined
  become: true

- name: "Storage service test (during upgrade only)"
  include_role:
    name: storage-tester
    apply:
      environment:
        KUBECONFIG: "{{ kubeconfig_path }}"
  vars:
    storage_class: "{{ tester_storage_class | default(omit) }}"
  when:
    - dci_main is defined
    - dci_main == 'upgrade'
    - storage_upgrade_tester | default(false) | bool
...

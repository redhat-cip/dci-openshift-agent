---
- name: "Get cluster version"
  community.kubernetes.k8s_info:
    api: config.openshift.io/v1
    kind: ClusterVersion
    name: version
  register: cluster_version

- name: "Get OCP version"
  vars:
    current_ver_query: "history[?state=='Completed'] | [0].version"
    full_ver: "{{ cluster_version.resources[0].status | json_query(current_ver_query) }}"
    current_ver: "{{ full_ver.split('-')[0] }}"
  set_fact:
    ocp_version: "{{  current_ver }}"
    ocp_version_maj: "{{ current_ver.split('.')[0] }}"
    ocp_version_min: "{{ current_ver.split('.')[1] }}"

- name: "Prepare operators and catalogs"
  include_tasks: prepare-operators.yml

- name: "Mirroring the NFS external storage provisioner image"
  include_role:
    name: mirror_images
  vars:
    images: ['registry.k8s.io/sig-storage/nfs-subdir-external-provisioner:v4.0.2']
    authfile: "{{ dci_pullsecret_file }}"
  when:
    - dci_disconnected | default(false) | bool
    - enable_nfs_storage | bool

- name: "Deploy NFS external storage"
  include_role:
    name: nfs-external-storage
  vars:
    nes_nfs_server: "{{ nfs_server }}"
    nes_nfs_path: "{{ nfs_path }}"
    nes_path_pattern: "{{ job_id is defined |
                        ternary( job_id+'_${.PVC.namespace}.${.PVC.name}', omit) }}"
    nes_provisioner_image: |-
      {%- if dci_disconnected | default(false) %}
      {{ dci_local_registry }}/sig-storage/nfs-subdir-external-provisioner:{{ nfs_subdir_external_provisioner_tag }}
      {%- else %}
      registry.k8s.io/sig-storage/nfs-subdir-external-provisioner:{{ nfs_subdir_external_provisioner_tag }}
      {%- endif %}
  when:
    - enable_nfs_storage | bool

- name: "Enable operators required for CNFs"
  set_fact:
    enable_sriov: true
    enable_perf_addon: true
  when: dci_prepare_cnf | bool

- name: "Deploy operators required by CNFs"
  block:
    - name: "deploy-operators : Get all worker nodes"
      community.kubernetes.k8s_info:
        kind: Node
        label_selectors:
          - "node-role.kubernetes.io/worker"
      register: nodes

    - name: "deploy-operators : test_ Check enough worker nodes availability"
      vars:
        worker_node_count: "{{ nodes.resources | length }}"
      fail:
        msg: "Not enough worker nodes ({{ worker_node_count }}) to perform required tasks"
      when:
        - worker_node_count | int <= 1
        - install_type != 'sno'
        - install_type != 'acm'

    - name: "deploy-operators : Increase maxUnavailable count to n-1"
      vars:
        worker_node_count: "{{ nodes.resources | length }}"
        mcp_def: |
          apiVersion: machineconfiguration.openshift.io/v1
          kind: MachineConfigPool
          metadata:
            name: worker
          spec:
            maxUnavailable: {{ worker_node_count | int - 1 }}
      community.kubernetes.k8s:
        state: present
        definition: "{{ mcp_def }}"
      when:
        - worker_node_count | int > 1

    - name: "deploy-operators : Override Red Hat catalog in connected"
      include_role:
        name: catalog-source
      vars:
        cs_name: "redhat-operators"
        cs_namespace: "openshift-marketplace"
        cs_image: "{{ operators_index }}"
        cs_publisher: "Red Hat"
      when:
        - operators_index is defined
        - not dci_disconnected | default(false) | bool

    - name: "deploy-operators : Install Performance Addon Operator"
      block:
        - name: "deploy-operators : Install Performance Addon Operator"
          include_role:
            name: olm-operator
          vars:
            operator: performance-addon-operator
            source: "{{ opm_catalog_source_name }}"
            namespace: openshift-performance-addon-operator
            ns_labels:
              openshift.io/cluster-monitoring: "true"
      when:
        - enable_perf_addon | bool
        - ocp_version is version("4.11", "<")

    - name: "deploy-operators : Install and configure SRIOV"
      block:
        - name: "deploy-operators : Install SRIOV operator"
          include_role:
            name: olm-operator
          vars:
            operator: sriov-network-operator
            source: "{{ upstream_source_catalog_name | default(opm_catalog_source_name) }}"
            namespace: openshift-sriov-network-operator
            operator_group_spec:
              targetNamespaces:
                - openshift-sriov-network-operator
            ns_labels:
              openshift.io/run-level: "1"

        - name: "configure-operators : Configure SRIOV operator"
          include_tasks: apply-sriov-config.yml

      when:
        - enable_sriov | bool

    - name: "deploy-operators : Reset maxUnavailable count to default value 1"
      community.kubernetes.k8s:
        definition:
          kind: MachineConfigPool
          metadata:
            name: worker
          spec:
            maxUnavailable: 1
  when: >
    (dci_prepare_cnf | bool) or
    (enable_perf_addon | bool ) or
    (enable_sriov | bool)

- name: Validate if the Performance Profile CRD is present
  community.kubernetes.k8s_info:
    api_version: apiextensions.k8s.io/v1
    kind: CustomResourceDefinition
    name: performanceprofiles.performance.openshift.io
  register: perf_profile_crd

- name: "configure-operators : Apply Performance Profile"
  include_tasks: apply-pao-profile.yml
  when:
    - performance_definition is defined
    - perf_profile_crd.resources|length > 0

- name: "Deploy CNV and HCO Operators"
  block:
    - name: "deploy-operators : Install CNV operator"
      include_role:
        name: olm-operator
      vars:
        operator: kubevirt-hyperconverged
        source: "{{ opm_catalog_source_name }}"
        namespace: openshift-cnv
        operator_group_spec:
          targetNamespaces:
            - openshift-cnv

    - name: "configure-operators : Deploy Hyperconverged Operator"
      include_role:
        name: hco-setup
      vars:
        hs_pullsecret_file: "{{ dci_pullsecret_file }}"
        hs_registry: "{{ dci_local_registry }}"
        hs_test_vm: "{{ dci_cnv_test | default(false) | bool }}"

  when:
    - enable_cnv | bool

- name: "deploy-operators : Install Elasticsearch operator"
  include_role:
    name: olm-operator
  vars:
    operator: elasticsearch-operator
    source: "{{ opm_catalog_source_name }}"
    namespace: openshift-operators-redhat
    ns_labels:
      openshift.io/cluster-monitoring: "true"
  when:
    - enable_elasticsearch | bool

- name: "deploy-operators : Install Cluster-logging operator"
  include_role:
    name: olm-operator
  vars:
    operator: cluster-logging
    source: "{{ opm_catalog_source_name }}"
    namespace: openshift-logging
    operator_group_spec:
      targetNamespaces:
        - openshift-logging
  when:
    - enable_logs_stack | bool or
      enable_clusterlogging | bool

- name: "deploy-operators : Install the Loki Operator"
  include_role:
    name: olm-operator
  vars:
    operator: loki-operator
    source: "{{ opm_catalog_source_name }}"
    namespace: openshift-operators-redhat
    ns_labels:
      openshift.io/cluster-monitoring: "true"
  when:
    - enable_logs_stack | bool

- name: ODF Installation and setup
  block:
    - name: "deploy-operators : Install ODF Operator"
      include_role:
        name: olm-operator
      vars:
        operator: odf-operator
        source: "{{ opm_catalog_source_name }}"
        namespace: openshift-storage
        ns_labels:
          openshift.io/cluster-monitoring: "true"
        operator_group_spec:
          targetNamespaces:
            - openshift-storage
      when:
        - enable_odf | bool

    - name: "deploy-operators : Install OCS Operator"
      include_role:
        name: olm-operator
      vars:
        operator: ocs-operator
        source: "{{ opm_catalog_source_name }}"
        namespace: openshift-storage
        ns_labels:
          openshift.io/cluster-monitoring: "true"
        operator_group_spec:
          targetNamespaces:
            - openshift-storage
      when:
        - enable_ocs | bool
        - not enable_odf | bool

    - name: "deploy-operators : Install LocalStorage Operator"
      include_role:
        name: olm-operator
      vars:
        operator: local-storage-operator
        source: "{{ opm_catalog_source_name }}"
        namespace: openshift-local-storage
        operator_group_spec:
          targetNamespaces:
            - openshift-local-storage
      when:
        - enable_lso | bool

    - name: "configure-operators : Deploy an ODF Cluster"
      include_role:
        name: odf-setup
      when:
        - enable_ocs | bool
        - storage_cluster | bool

  when: (enable_lso | bool) or (enable_ocs | bool)

- name: "Setup OCP logging stack"
  block:
    - name: "Mirroring the event router image"
      include_role:
        name: mirror_images
      vars:
        images: ["registry.redhat.io/openshift-logging/eventrouter-rhel8:{{ eventrouter_rhel_tag }}"]
        authfile: "{{ dci_pullsecret_file }}"
      when:
        - dci_disconnected | default(false) | bool

    - name: "Setup OCP logging stack"
      include_role:
        name: ocp-logging
      vars:
        ol_access_key_id: "{{ logs_access_key_id }}"
        ol_access_key_secret: "{{ logs_access_key_secret }}"
        ol_bucket: "{{ logs_bucket }}"
        ol_endpoint: "{{ logs_endpoint }}"
        ol_region: "{{ logs_region }}"
        ol_loki_size: "{{ logs_loki_size }}"
        ol_storage_class: "{{ logs_storage_class }}"
        ol_event_router_image: |-
          {%- if dci_disconnected | default(false) %}
          {{ dci_local_registry }}/openshift-logging/eventrouter-rhel8:{{ eventrouter_rhel_tag }}
          {%- else %}
          registry.redhat.io/openshift-logging/eventrouter-rhel8:{{ eventrouter_rhel_tag }}
          {%- endif %}
  when:
    - enable_logs_stack | bool

- name: "Deploy and configure the Advanced Cluster Manager"
  vars:
    acm_namespace: open-cluster-management
    acm_instance: multiclusterhub
  block:
    - name: "deploy-operators : Install the ACM operator"
      include_role:
        name: olm-operator
      vars:
        operator: advanced-cluster-management
        source: "{{ opm_catalog_source_name }}"
        namespace: "{{ acm_namespace }}"
        operator_group_spec:
          targetNamespaces:
            - "{{ acm_namespace }}"
  when:
    - enable_acm | bool

- name: "deploy-operators : Install and configure the Node Discovery Operator"
  vars:
    nfd_namespace: "openshift-nfd"
    nfd_instance_name: "nfd-instance"
    nfd_image_tag: "v{{ version.split('.')[:2] | join('.') }}"
  block:
    - name: "deploy-operators : Install the Node Discovery Operator"
      include_role:
        name: olm-operator
      vars:
        operator: nfd
        source: "{{ opm_catalog_source_name }}"
        namespace: "{{ nfd_namespace }}"
        ns_labels:
          openshift.io/cluster-monitoring: "true"
        operator_group_spec:
          targetNamespaces:
            - "{{ nfd_namespace }}"

    - name: "Get the release ose-node-feature-discovery image digest"
      shell:
        cmd: >
          skopeo inspect
          --no-tags
          {% if dci_pullsecret_file is defined %}
          --authfile {{ dci_pullsecret_file }}
          {% endif %}
          docker://registry.redhat.io/openshift4/ose-node-feature-discovery:{{ nfd_image_tag }} |
          jq -r '.Digest'
      register: nfd_digest

    - name: "deploy-operators : Configure the Node Discovery Operator"
      vars:
        image_ref: "{{  dci_disconnected | default(false) | bool |
                    ternary('ose-node-feature-discovery@'+nfd_digest.stdout,
                    'ose-node-feature-discovery:'+nfd_image_tag) }}"
        ndf_def: |
          apiVersion: nfd.openshift.io/v1
          kind: NodeFeatureDiscovery
          metadata:
            name: "{{ nfd_instance_name }}"
            namespace: "{{ nfd_namespace }}"
          spec:
            instance: "" # instance is empty by default
            topologyupdater: false # False by default
            operand:
              image: registry.redhat.io/openshift4/{{ image_ref }}
              imagePullPolicy: Always
            workerConfig:
              configData: |
                sources:
                  cpu:
                    cpuid:
                      attributeBlacklist:
                        - "BMI1"
                        - "BMI2"
                        - "CLMUL"
                        - "CMOV"
                        - "CX16"
                        - "ERMS"
                        - "F16C"
                        - "HTT"
                        - "LZCNT"
                        - "MMX"
                        - "MMXEXT"
                        - "NX"
                        - "POPCNT"
                        - "RDRAND"
                        - "RDSEED"
                        - "RDTSCP"
                        - "SGX"
                        - "SSE"
                        - "SSE2"
                        - "SSE3"
                        - "SSE4.1"
                        - "SSE4.2"
                        - "SSSE3"
                      attributeWhitelist:
                  kernel:
                    configOpts:
                      - "NO_HZ"
                      - "X86"
                      - "DMI"
                  pci:
                    deviceClassWhitelist:
                      - "0200"
                      - "03"
                      - "12"
                    deviceLabelFields:
                      - "class"
            customConfig:
              configData: |
                    - name: "more.kernel.features"
                      matchOn:
                      - loadedKMod: ["example_kmod3"]
      community.kubernetes.k8s:
        state: present
        definition: "{{ ndf_def }}"

    - name: "Wait for NFD pods to be Running"
      community.kubernetes.k8s_info:
        api_version: v1
        kind: Pod
        namespace: "{{ nfd_namespace }}"
      register: pod_list
      until: pod_list|json_query('resources[*].status.phase')|unique == ["Running"]
      retries: 20
      delay: 15
  when:
    - enable_nfd | bool

- name: "deploy-operators : Install the MetalLB operator"
  include_role:
    name: olm-operator
  vars:
    operator: metallb-operator
    source: "{{ opm_catalog_source_name }}"
    namespace: metallb-system
  when:
    - enable_mlb | bool

- name: Deploy k8s NMState operator
  vars:
    nmstate_namespace: openshift-nmstate
  block:
    - name: "deploy-operators : Install the k8s NMState Operator"
      include_role:
        name: olm-operator
      vars:
        operator: kubernetes-nmstate-operator
        source: "{{ opm_catalog_source_name }}"
        namespace: "{{ nmstate_namespace }}"
        operator_group_spec:
          targetNamespaces:
            - "{{ nmstate_namespace }}"

    - name: Initialize instance
      community.kubernetes.k8s:
        definition:
          apiVersion: nmstate.io/v1
          kind: NMState
          metadata:
            name: nmstate
  when:
    - enable_nmstate | bool

# GitOps Operator is used for ZTP, in combination with ACM, so
# both must be enabled.
- name: "deploy-operators : Install the GitOps Operator"
  include_role:
    name: olm-operator
  vars:
    operator: openshift-gitops-operator
    source: "{{ opm_catalog_source_name }}"
    namespace: openshift-gitops
  when:
    - enable_acm | bool
    - enable_gitops | bool

- name: "deploy-operators : All operators from a catalog"
  include_tasks: all-from-catalog.yml
  when:
    - install_all_from_catalog | default('') | length

- name: "deploy-operators : Deploy other operators playbook"
  include_tasks: deploy-custom-operator.yml
  when:
    - dci_operators is defined
    - dci_operators | length
  loop: "{{ dci_operators }}"
  loop_control:
    loop_var: dci_operator
    label: "{{ dci_operator.name }}"

- name: "deploy-operators : Create defined Custom Resources"
  include_role:
    name: deploy-cr
  vars:
    api_version: "{{ item.api_version }}"
    kind: "{{ item.kind }}"
    namespace: "{{ item.namespace }}"
    name: "{{ item.name }}"
    spec: "{{ item.spec }}"
  with_list: "{{ dci_ocp_custom_resources }}"
  when:
    - dci_ocp_custom_resources is defined
    - dci_ocp_custom_resources is list

- name: "Setup Advanced Cluster Management"
  include_role:
    name: acm-setup
  vars:
    hub_disconnected: "{{ dci_disconnected | default(false) | bool }}"
  when:
    - enable_acm | bool

...
